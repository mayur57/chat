## chat

Chat frontend for interfacing with locally hosted Ollama models and more. Hook it up to your LLM server and use it as a custom UI.

I personally use it with **Raspberry Pi 5** + Ollama.
**LLM**: Google DeepMind's Gemma-2 2B

<img width="1460" height="1616" alt="image" src="https://github.com/user-attachments/assets/ed29caa7-51eb-4c33-a0da-14254d37a401" />
